#!/bin/sh --login                 
#SBATCH --array=250-7708:1000                 
#SBATCH --time=50:00:00                 
#SBATCH --ntasks=2                 
#SBATCH --cpus-per-task=2                 
#SBATCH --mem=20G                 
#SBATCH --job-name RF_FS_job_YPDMV                 
#SBATCH --output=%x_%A_%a.out                 
cd /mnt/scratch/seguraab/yeast_project/ORF_yeast_RF_results                 
module purge                 
module load GCC/6.4.0-2.28  OpenMPI/2.1.2  Python/3.6.4                 
trait=YPDMV                 
path1=/mnt/home/seguraab/Shiu_Lab/Project/External_software/ML-Pipeline                 
path2=/mnt/scratch/seguraab/yeast_project/ORF_yeast_RF_results                 
path3=/mnt/home/seguraab/Shiu_Lab/Project/Data/Peter_2018                 
start_ind=$SLURM_ARRAY_TASK_ID                 
end_ind=$(( $start_ind + 1000 - 250))                  
echo "this job start from $start_ind to $end_ind"                 
for i in `seq $start_ind 250 $end_ind`; do
	python ${path1}/ML_regression.py -df ${path3}/ORFs_pres_abs.csv -df2 ${path3}/pheno.csv -y_name ${trait} -sep , -feat ${path2}/feat_rf_${trait}_top_$i -test ${path3}/Test.txt -alg RF -n_jobs 12 -n 100 -cv_num 5 -save ${trait}_orf_$i -plots t
done
                 
scontrol show job $SLURM_JOB_ID