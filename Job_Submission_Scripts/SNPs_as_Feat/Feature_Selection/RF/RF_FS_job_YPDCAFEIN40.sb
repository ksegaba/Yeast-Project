#!/bin/sh --login                 
#SBATCH --array=500-50000:2500 # 20 array tasks; 5000 for 10 tasks                 
#SBATCH --time=100:00:00                 
#SBATCH --ntasks=2                 
#SBATCH --cpus-per-task=2                 
#SBATCH --mem=20G                 
#SBATCH --job-name RF_FS_job_YPDCAFEIN40                 
#SBATCH --output=%x_%A_%a.out                 
cd /mnt/scratch/seguraab/yeast_project/yeast_rf_results                 
module purge                 
module load GCC/6.4.0-2.28  OpenMPI/2.1.2  Python/3.6.4                 
trait=YPDCAFEIN40                 
start_ind=$SLURM_ARRAY_TASK_ID                 
end_ind=$(( $start_ind + 2000)) #+ 4500 for 10 tasks                  
echo "this job start from $start_ind to $end_ind"                 
for i in `seq $start_ind 500 $end_ind`; do                 
    python /mnt/home/seguraab/Shiu_Lab/Project/External_software/ML-Pipeline/ML_regression.py -df /mnt/scratch/seguraab/yeast_project/yeast_rf_results/geno_rf_YPDCAFEIN40.csv -sep , -feat /mnt/scratch/seguraab/yeast_project/yeast_rf_results/feat_rf_YPDCAFEIN40_top_$i -test /mnt/home/seguraab/Shiu_Lab/Project/Data/Peter_2018/Test.txt -alg RF -n_jobs 12 -n 100 -cv_num 5 -save YPDCAFEIN40_rf_$i -plots t                 
done
                 
scontrol show job $SLURM_JOB_ID